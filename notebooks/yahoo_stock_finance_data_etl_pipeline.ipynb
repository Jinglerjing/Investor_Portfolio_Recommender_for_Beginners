{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to automate the ETL\n",
    "This module provides a set of reusable Python functions to automate the ETL (Extract, Transform, Load) process for stock market datasets. It supports:\n",
    "Extracting historical trading data and company metadata from Yahoo Finance\n",
    "\n",
    "Transforming and cleaning raw data (handling formatting issues, parsing dates, and converting values)\n",
    "\n",
    "Loading and consolidating sector-specific datasets into clean CSV files ready for analysis\n",
    "\n",
    "The run_etl_pipeline() function orchestrates the entire workflow for any list of stock tickers by sector, simplifying data preparation for financial analysis or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data from Yahoo Finance\n",
    "\n",
    "import os\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "def download_trading_data(tickers, save_path, start=\"2020-01-01\", end=\"2025-05-20\"):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    for ticker in tickers:\n",
    "        print(f\"Downloading {ticker}...\")\n",
    "        try:\n",
    "            df = yf.download(ticker, start=start, end=end)\n",
    "            if not df.empty:\n",
    "                df.to_csv(os.path.join(save_path, f\"{ticker}.csv\"))\n",
    "                print(f\"Saved: {ticker}.csv\")\n",
    "            else:\n",
    "                print(f\"No data for {ticker}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {ticker}: {e}\")\n",
    "            \n",
    "\n",
    "def fetch_metadata(tickers, save_path):\n",
    "    metadata_list = []\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            info = yf.Ticker(ticker).info\n",
    "            metadata_list.append({\n",
    "                \"ticker\": ticker,\n",
    "                \"sector\": info.get(\"sector\"),\n",
    "                \"industry\": info.get(\"industry\"),\n",
    "                \"marketCap\": info.get(\"marketCap\"),\n",
    "                \"beta\": info.get(\"beta\"),\n",
    "                \"dividendYield\": info.get(\"dividendYield\"),\n",
    "                \"trailingPE\": info.get(\"trailingPE\"),\n",
    "                \"forwardPE\": info.get(\"forwardPE\"),\n",
    "                \"earningsQuarterlyGrowth\": info.get(\"earningsQuarterlyGrowth\"),\n",
    "                \"fullTimeEmployees\": info.get(\"fullTimeEmployees\"),\n",
    "                \"country\": info.get(\"country\"),\n",
    "                \"website\": info.get(\"website\")\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving data for {ticker}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(metadata_list)\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved metadata to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform and clean raw data\n",
    "def clean_trading_data(df):\n",
    "    df = df[~df['Price'].isin(['Ticker', 'Date', 'Close', 'High', 'Low', 'Open', 'Volume'])].copy()\n",
    "    df['Price'] = pd.to_datetime(df['Price'], errors='coerce')\n",
    "    df.rename(columns={'Price': 'Date'}, inplace=True)\n",
    "    df = df.dropna(subset=['Date'])\n",
    "    numeric_cols = ['Close', 'High', 'Low', 'Open', 'Volume']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and consolidate\n",
    "\n",
    "def merge_csvs(folder_path, keyword, output_file):\n",
    "    files = [f for f in os.listdir(folder_path) if keyword in f.lower()]\n",
    "    dfs = [pd.read_csv(os.path.join(folder_path, f)) for f in files]\n",
    "    merged = pd.concat(dfs, ignore_index=True)\n",
    "    merged.to_csv(os.path.join(folder_path, output_file), index=False)\n",
    "    print(f\"Merged CSV saved to {output_file}\")\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_etl_pipeline() - Required Parameters: list of tickers, based_folder (The folder where all data will be saved), start, end, sector_name)\n",
    "\n",
    "def run_etl_pipeline(tickers, base_folder, sector_name, start=\"2020-01-01\", end=\"2025-05-20\"):\n",
    "    import os\n",
    "\n",
    "    print(f\"ðŸš€ Starting ETL pipeline for sector: {sector_name}\")\n",
    "\n",
    "    # 1. Define paths\n",
    "    trading_path = os.path.join(base_folder, sector_name, \"trading_data\")\n",
    "    metadata_path = os.path.join(base_folder, sector_name, f\"{sector_name}_metadata.csv\")\n",
    "    merged_path = os.path.join(base_folder, sector_name, f\"{sector_name}_merged_trading_data.csv\")\n",
    "\n",
    "    # 2. Download trading data\n",
    "    download_trading_data(tickers, trading_path, start, end)\n",
    "\n",
    "    # 3. Fetch and save metadata\n",
    "    fetch_metadata(tickers, metadata_path)\n",
    "\n",
    "    # 4. Merge trading CSVs\n",
    "    merged_df = merge_csvs(trading_path, keyword=\".csv\", output_file=f\"{sector_name}_merged_trading_data.csv\")\n",
    "\n",
    "    # 5. Clean merged trading data\n",
    "    cleaned_df = clean_trading_data(merged_df)\n",
    "\n",
    "    # 6. Save cleaned trading data\n",
    "    cleaned_path = os.path.join(base_folder, sector_name, f\"{sector_name}_cleaned_trading_data.csv\")\n",
    "    cleaned_df.to_csv(cleaned_path, index=False)\n",
    "\n",
    "    print(f\"âœ… ETL completed for sector: {sector_name}\")\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
