{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is to show how to scrap stock data through yfinance, merge and clean them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example with 2 sectors\n",
    "data = [\n",
    "    # Technology sector\n",
    "    {\"Sector\": \"Technology\", \"Ticker\": \"AAPL\", \"Company Name\": \"Apple Inc.\"},\n",
    "    {\"Sector\": \"Technology\", \"Ticker\": \"MSFT\", \"Company Name\": \"Microsoft Corporation\"},\n",
    "    {\"Sector\": \"Technology\", \"Ticker\": \"GOOGL\", \"Company Name\": \"Alphabet Inc.\"},\n",
    "    {\"Sector\": \"Technology\", \"Ticker\": \"NVDA\", \"Company Name\": \"NVIDIA Corporation\"},\n",
    "    {\"Sector\": \"Technology\", \"Ticker\": \"ADBE\", \"Company Name\": \"Adobe Inc.\"},\n",
    "\n",
    "    # Healthcare sector\n",
    "    {\"Sector\": \"Healthcare\", \"Ticker\": \"PFE\", \"Company Name\": \"Pfizer Inc.\"},\n",
    "    {\"Sector\": \"Healthcare\", \"Ticker\": \"JNJ\", \"Company Name\": \"Johnson & Johnson\"},\n",
    "    {\"Sector\": \"Healthcare\", \"Ticker\": \"LLY\", \"Company Name\": \"Eli Lilly and Company\"},\n",
    "    {\"Sector\": \"Healthcare\", \"Ticker\": \"MRK\", \"Company Name\": \"Merck & Co., Inc.\"},\n",
    "    {\"Sector\": \"Healthcare\", \"Ticker\": \"ABT\", \"Company Name\": \"Abbott Laboratories\"}\n",
    "    \n",
    "    # Add more names if you'd like\n",
    "]\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "df = pd.DataFrame(data)\n",
    "output_path = \"/mnt/data/stock_sector_list_example.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of all my tickers\n",
    "tickers = [\n",
    "    #Technology\n",
    "    'AAPL', 'MSFT', 'AMD', 'ADBE', 'AVGO', 'INTC', 'CRM', 'CSCO', 'NVDA', 'ORCL', \n",
    "    'QCOM', 'PLTR', 'IBM', 'NOW', 'TXN', 'CDNS', 'ASML', 'GFS', 'APP', 'ANSS', \n",
    "    \n",
    "    #Healthcare\n",
    "    'ABBV', 'ABT', 'AMGN', 'JNJ', 'PFE', 'LLY', 'MRK', 'GEHC', 'ISRG', 'MDT', \n",
    "    'DHR', 'GILD', 'BIIB', 'DXCM', 'IDXX', 'BMY', 'TMO', 'AZN', 'HCA', 'CVS', \n",
    "    \n",
    "    #Financials\n",
    "    'AIG', 'AXP', 'BAC', 'BK', 'C', 'GS', 'JPM', 'MA', 'MET', 'MS', \n",
    "    'PYPL', 'SCHW', 'USB', 'V', 'BRK.B', 'COF', 'BLK', 'TROW', 'PGR', 'FITB', \n",
    "    \n",
    "    #Consumer Discretionary\n",
    "    'AMZN', 'TSLA', 'HD', 'MCD', 'BKNG', 'GM', 'LOW', 'NKE', 'SBUX', 'TGT', \n",
    "    'DIS', 'ABNB', 'YUM', 'ROST', 'TJX', 'ULTA', 'F', 'EBAY', 'ETSY', 'BBY', \n",
    "    \n",
    "    #Consumer Staples\n",
    "    'CL', 'COST', 'KO', 'MDLZ', 'MO', 'PG', 'PEP', 'WMT', 'KDP', 'CLX', \n",
    "    'KR', 'UNFI', 'GIS', 'TSN', 'SYY', 'ADM', 'KMB', 'EL', 'HSY', 'CHD',\n",
    "    \n",
    "    #Energy\n",
    "    'COP', 'CVX', 'XOM', 'FANG', 'BKR', 'EOG', 'OXY', 'PSX', 'HAL', 'SLB', \n",
    "    'VLO', 'HES', 'DVN', 'MPC', 'APA', 'CPE', 'SM', 'MTDR', 'PDCE',  'PXD',\n",
    "    \n",
    "    #Industrials\n",
    "    'BA', 'CAT', 'DE', 'EMR', 'FDX', 'GD', 'HON', 'LMT', 'UNP', 'UPS', \n",
    "    'CSX', 'ADP', 'MMM', 'RTX', 'GE', 'SWK', 'ITW', 'ETN', 'IR', 'PCAR', \n",
    "    \n",
    "    #Communication Services\n",
    "    'DIS','GOOG', 'GOOGL', 'META', 'CMCSA', 'T', 'TMUS', 'CHTR', 'NFLX', 'VZ', \n",
    "    'SIRI', 'PARA', 'FOXA', 'WBD', 'TTWO', 'ATVI', 'LYV', 'BIDU', 'NTES', 'SPOT', \n",
    "    \n",
    "    #Utilities\n",
    "    'DUK', 'NEE', 'SO', 'EXC', 'CEG', 'XEL', 'AEP', 'ES', 'D', 'NRG', \n",
    "    'PPL', 'PEG', 'ED', 'EVRG', 'EIX', 'WEC', 'AWK', 'ATO', 'SRE', 'CMS', \n",
    "    \n",
    "    #Real Estate\n",
    "    'AMT', 'CSGP', 'SPG', 'WELL', 'O', 'PLD', 'BXP', 'EQIX', 'PSA', 'EQR', \n",
    "    'VNO', 'SLG', 'AVB', 'FRT', 'OHI', 'DLR', 'HST', 'WY', 'IRM', 'ARE', \n",
    "    \n",
    "    #Materials\n",
    "    'LIN', 'DD', 'ECL', 'FCX', 'NEM', 'APD', 'MOS', 'PPG', 'RPM', 'CE', \n",
    "    'EMN', 'ALB', 'VMC', 'CF', 'TREX', 'MLM', 'IFF', 'NUE', 'AVY', 'BALL']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Meta info of all companies (sector by sector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script allows you to fetch companies' meta info, such as sector, industry, marketcap, dividend yield, etc... you can fetch all the tickers at the same time, or sector by sector and save them individually to your local disk so that you can merge the data with the day trading data (see next script) to do analysis from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching metadata for AMZN...\n",
      "Fetching metadata for TSLA...\n",
      "Fetching metadata for HD...\n",
      "Fetching metadata for MCD...\n",
      "Fetching metadata for BKNG...\n",
      "Fetching metadata for GM...\n",
      "Fetching metadata for LOW...\n",
      "Fetching metadata for NKE...\n",
      "Fetching metadata for SBUX...\n",
      "Fetching metadata for TGT...\n",
      "Fetching metadata for DIS...\n",
      "Fetching metadata for ABNB...\n",
      "Fetching metadata for YUM...\n",
      "Fetching metadata for ROST...\n",
      "Fetching metadata for TJX...\n",
      "Fetching metadata for ULTA...\n",
      "Fetching metadata for F...\n",
      "Fetching metadata for EBAY...\n",
      "Fetching metadata for ETSY...\n",
      "Fetching metadata for BBY...\n",
      "Saved to /Users/xiejing/Desktop/Codeoptest/Personal_Project/Consumer_Discretionary_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "    \n",
    "tickers = ['AMZN', 'TSLA', 'HD', 'MCD', 'BKNG', 'GM', 'LOW', 'NKE', 'SBUX', 'TGT', \n",
    "    'DIS', 'ABNB', 'YUM', 'ROST', 'TJX', 'ULTA', 'F', 'EBAY', 'ETSY', 'BBY']\n",
    "metadata_list = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"Fetching metadata for {ticker}...\")\n",
    "    try:\n",
    "        t = yf.Ticker(ticker)\n",
    "        info = t.info\n",
    "        selected_info = {\n",
    "            \"ticker\": ticker,\n",
    "            \"sector\": info.get(\"sector\"),\n",
    "            \"industry\": info.get(\"industry\"),\n",
    "            \"marketCap\": info.get(\"marketCap\"),\n",
    "            \"beta\": info.get(\"beta\"),\n",
    "            \"dividendYield\": info.get(\"dividendYield\"),\n",
    "            \"trailingPE\": info.get(\"trailingPE\"),\n",
    "            \"forwardPE\": info.get(\"forwardPE\"),\n",
    "            \"earningsQuarterlyGrowth\": info.get(\"earningsQuarterlyGrowth\"),\n",
    "            \"fullTimeEmployees\": info.get(\"fullTimeEmployees\"),\n",
    "            \"country\": info.get(\"country\"),\n",
    "            \"website\": info.get(\"website\")\n",
    "        }\n",
    "        metadata_list.append(selected_info)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {ticker}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(metadata_list)\n",
    "\n",
    "# Save to specified path\n",
    "output_path = r\"/Users/xiejing/Desktop/Codeoptest/Personal_Project/Consumer_Discretionary_metadata.csv\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day Trading Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading AIG...\n",
      "Saved: AIG.csv\n",
      "Downloading AXP...\n",
      "Saved: AXP.csv\n",
      "Downloading BAC...\n",
      "Saved: BAC.csv\n",
      "Downloading BK...\n",
      "Saved: BK.csv\n",
      "Downloading C...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C.csv\n",
      "Downloading GS...\n",
      "Saved: GS.csv\n",
      "Downloading JPM...\n",
      "Saved: JPM.csv\n",
      "Downloading MA...\n",
      "Saved: MA.csv\n",
      "Downloading MET...\n",
      "Saved: MET.csv\n",
      "Downloading MS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: MS.csv\n",
      "Downloading PYPL...\n",
      "Saved: PYPL.csv\n",
      "Downloading SCHW...\n",
      "Saved: SCHW.csv\n",
      "Downloading USB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['BRK.B']: YFTzMissingError('possibly delisted; no timezone found')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: USB.csv\n",
      "Downloading V...\n",
      "Saved: V.csv\n",
      "Downloading BRK.B...\n",
      "No data for BRK.B\n",
      "Downloading COF...\n",
      "Saved: COF.csv\n",
      "Downloading BLK...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: BLK.csv\n",
      "Downloading TROW...\n",
      "Saved: TROW.csv\n",
      "Downloading PGR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: PGR.csv\n",
      "Downloading FITB...\n",
      "Saved: FITB.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import os\n",
    "\n",
    "tickers = ['AIG', 'AXP', 'BAC', 'BK', 'C', 'GS', 'JPM', 'MA', 'MET', 'MS',\n",
    "           'PYPL', 'SCHW', 'USB', 'V', 'BRK.B', 'COF', 'BLK', 'TROW', 'PGR', 'FITB']\n",
    "save_path = r\"/Users/xiejing/Desktop/Codeoptest/Personal_Project\"\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "for ticker in tickers:\n",
    "    print(f\"Downloading {ticker}...\")\n",
    "    try:\n",
    "        df = yf.download(ticker, start=\"2020-01-01\", end=\"2025-05-20\")\n",
    "        if not df.empty:\n",
    "            df.to_csv(os.path.join(save_path, f\"{ticker}.csv\"))\n",
    "            print(f\"Saved: {ticker}.csv\")\n",
    "        else:\n",
    "            print(f\"No data for {ticker}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {ticker}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read /Users/xiejing/Desktop/Codeoptest/Personal_Project/BRK.B.csv: [Errno 2] No such file or directory: '/Users/xiejing/Desktop/Codeoptest/Personal_Project/BRK.B.csv'\n",
      "Saved merged CSV to /Users/xiejing/Desktop/Codeoptest/Personal_Project/20_Financials_companies_nasdq_trading_data_2020.01-2025.05.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "tickers = ['AIG', 'AXP', 'BAC', 'BK', 'C', 'GS', 'JPM', 'MA', 'MET', 'MS',\n",
    "           'PYPL', 'SCHW', 'USB', 'V', 'BRK.B', 'COF', 'BLK', 'TROW', 'PGR', 'FITB']\n",
    "folder_path = r\"/Users/xiejing/Desktop/Codeoptest/Personal_Project\"\n",
    "combined = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    file_path = os.path.join(folder_path, f\"{ticker}.csv\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['Ticker'] = ticker\n",
    "        combined.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {file_path}: {e}\")\n",
    "\n",
    "if combined:\n",
    "    merged_df = pd.concat(combined, ignore_index=True)\n",
    "    output_path = os.path.join(folder_path, \"20_Financials_companies_nasdq_trading_data_2020.01-2025.05.csv\")\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved merged CSV to {output_path}\")\n",
    "else:\n",
    "    print(\"No data files found or loaded.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
